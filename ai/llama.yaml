---
- name: Build llama.cpp
  hosts: kosmos.xeno
  tasks:
    - name: Copy PKGBUILD
      ansible.builtin.copy:
        src: "pkg-llama-cpp"
        dest: "/tmp/"

    - name: Build package
      ansible.builtin.command:
        cmd: makepkg -sr --noconfirm -f
        chdir: /tmp/pkg-llama-cpp
        creates: "/tmp/pkg-llama-cpp/llama.cpp-git-*-x86_64.pkg.tar.zst"

    - name: What package did I build?
      register: package_file_proc
      ansible.builtin.shell:
        cmd: "ls -1 llama.cpp-git-*-x86_64.pkg.tar.zst | fgrep -v debug"
        chdir: "/tmp/pkg-llama-cpp"

    - set_fact:
        package_file: "{{ package_file_proc.stdout }}"

    - debug:
        msg: "Built package {{ package_file }}"

- name: Setup LLM
  hosts: kosmos.xeno
  become: yes
  vars:
    profile: assistant
    package_file: "{{ hostvars['kosmos.xeno']['package_file'] }}"
  tasks:
    - name: Install package
      community.general.pacman:
        name: "/tmp/pkg-llama-cpp/{{ package_file }}"
        state: present
    - name: Remove package build files
      ansible.builtin.file:
        path: /tmp/pkg-llama-cpp
        state: absent
    - name: Copy llama server API key config
      ansible.builtin.copy:
        src: "files/llama.cpp-apikey.conf"
        dest: "/etc/llama.cpp-apikey.conf"
        owner: llama
        group: llama
        mode: 0600
# The model-related configs are installed in llm.yaml.
